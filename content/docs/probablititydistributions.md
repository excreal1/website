+++
title = 'Probablitity Distributions'
date = 2024-06-03T03:39:54Z
draft = false
+++

### Probability Distributions

1. **Random Variable**: 
   - A random variable is a function that maps outcomes of a random process to numerical values. It represents the possible results of an experiment, where each result has a probability of occurring.
   - Random variables can be categorized as either discrete or continuous, depending on whether their possible values are countable or uncountable.

2. **Probability Distribution**:
   - A probability distribution provides the probabilities of all possible outcomes of a random variable. It describes the likelihood of each outcome occurring.
   - In a discrete probability distribution, the probabilities are associated with individual values of the random variable. In a continuous probability distribution, probabilities are associated with intervals of values.
   - Probability distributions can be represented using probability mass functions (for discrete distributions) or probability density functions (for continuous distributions).

3. **Types of Probability Distributions**:
   - **Discrete Probability Distribution**: 
     - Deals with random variables that have a finite or countably infinite number of possible outcomes.
     - Examples include the **binomial distribution**, which describes the number of successes in a fixed number of independent Bernoulli trials, and the **Poisson distribution**, which models the number of events occurring in a fixed interval of time or space.
   - **Continuous Probability Distribution**: 
     - Deals with random variables that can take any value within a certain range.
     - Examples include the **normal distribution**, which describes continuous phenomena with a symmetric, bell-shaped curve, and the **uniform distribution**, where all intervals of the same length have the same probability.

4. **Normal Distribution**:
   - The normal distribution is characterized by its bell-shaped curve, with the majority of values clustered around the mean.
   - It is fully described by two parameters: the mean (μ) and the standard deviation (σ).
   - Many natural processes, such as heights, weights, and test scores, approximate a normal distribution due to the central limit theorem.

5. **Standard Normal Distribution**:
   - The standard normal distribution is a special case of the normal distribution with a mean of 0 and a standard deviation of 1.
   - Standardizing a normal distribution involves transforming it into a standard normal distribution using the formula: $Z = \frac{X - \mu}{\sigma}$, where $X$ is the value from the original distribution, $\mu$ is the mean of the original distribution, $\sigma$ is the standard deviation of the original distribution, and $Z$ is the standardized value.

6. **Central Limit Theorem**:
   - The Central Limit Theorem states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the shape of the population distribution.
   - This theorem is crucial for many inferential statistical methods, as it allows us to make inferences about population parameters based on sample statistics.

7. **Applications**:
   - Probability distributions are used in various fields, including finance, engineering, biology, and social sciences, to model and analyze random phenomena.
   - They form the basis for statistical inference, hypothesis testing, and estimation.

Understanding probability distributions lays the groundwork for many inferential statistical techniques. It's essential to grasp the properties and characteristics of different distributions to effectively analyze and interpret data in real-world scenarios.
